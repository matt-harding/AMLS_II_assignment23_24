{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e933245-f0f9-4c0c-abdf-93f4265f0540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhaleClassifier(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=200704, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=30, bias=True)\n",
       "  (embedding): Embedding(30, 30)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import save, load\n",
    "\n",
    "class WhaleDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_names = self.data['image'].tolist()\n",
    "        self.labels = self.data['species'].tolist()\n",
    "        self.classes = self.data['species'].unique()\n",
    "        self.encode = {k: i for i,k in enumerate(self.classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        image_name = os.path.join(self.image_dir, self.image_names[idx])\n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "        label = self.encode[self.labels[idx]]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = WhaleDataset(csv_file='filtered_train.csv', image_dir='train_images', transform=transform)\n",
    "num_classes = dataset.data['species'].nunique()\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_names = os.listdir(image_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = os.path.join(self.image_dir, self.image_names[idx])\n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, image_name\n",
    "\n",
    "class WhaleClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(WhaleClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.embedding = nn.Embedding(num_classes, num_classes)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        if labels is not None:\n",
    "            out = self.embedding(labels).squeeze(1)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = WhaleClassifier(num_classes)\n",
    "model.load_state_dict(torch.load('model_state.pt'))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c25d38b-df73-4925-b2d6-6d089303eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, total = 0, 0\n",
    "\n",
    "df = pd.read_csv('filtered_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ff25b00-2dba-477a-aae0-702d61a2cb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "melon_headed_whale\n",
      "beluga\n",
      "cuviers_beaked_whale\n",
      "beluga\n",
      "beluga\n",
      "beluga\n",
      "blue_whale\n",
      "spinner_dolphin\n",
      "pantropic_spotted_dolphin\n",
      "bottlenose_dolphin\n",
      "spinner_dolphin\n",
      "bottlenose_dolphin\n",
      "humpback_whale\n",
      "humpback_whale\n",
      "false_killer_whale\n",
      "beluga\n",
      "beluga\n",
      "bottlenose_dolpin\n",
      "kiler_whale\n",
      "humpback_whale\n",
      "long_finned_pilot_whale\n",
      "humpback_whale\n",
      "killer_whale\n",
      "blue_whale\n"
     ]
    }
   ],
   "source": [
    "inference_dataset = InferenceDataset(image_dir='inference_images', transform=transform)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, image_names in inference_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        reverse_encode = {v: k for k, v in dataset.encode.items()}\n",
    "        predicted_labels = [reverse_encode[label.item()] for label in predicted]\n",
    "\n",
    "        # Process the predictions and image names here\n",
    "        for image_name, predicted_label in zip(image_names, predicted_labels):\n",
    "            # Do something with the image name and predicted label\n",
    "            # print(f\"Image: {image_name}, Predicted Label: {predicted_label}\")\n",
    "            image_name = image_name.replace('inference_images/', '')\n",
    "            actual_label = df.loc[df['image'] == image_name, 'species'].values[0]\n",
    "\n",
    "            if actual_label == predicted_label:\n",
    "                correct += 1\n",
    "\n",
    "            total += 1\n",
    "\n",
    "print(f'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4200e37-6dc2-4b27-aec5-765026b30343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
